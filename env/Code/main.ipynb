{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kidney Stone Prediction based on Urine Analysis\n",
    "\n",
    "## Task: Develop ML/DL models to predict occurrence of kidney stones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "\n",
    "This dataset can be used to predict the presence of kidney stones based on urine analysis.\n",
    "\n",
    "The `79 urine specimens`, were analyzed in an effort to\n",
    "determine if certain `physical characteristics of the urine` might be related to the\n",
    "formation of `calcium oxalate crystals`.\n",
    "\n",
    "The `six physical characteristics` of the urine are: \n",
    "\n",
    "- `(1) specific gravity`, the density of the urine relative to water;\n",
    "- `(2) pH`, the negative logarithm of the hydrogen ion; \n",
    "- `(3) osmolarity (mOsm)`, a unit used in biology and medicine but not in\n",
    "physical chemistry. Osmolarity is proportional to the concentration of\n",
    "molecules in solution;\n",
    "- `(4) conductivity (mMho milliMho)`. One Mho is one reciprocal Ohm.\n",
    "Conductivity is proportional to the concentration of charged\n",
    "ions in solution; \n",
    "- `(5) urea concentration in millimoles per litre`;\n",
    "- `(6) calcium concentration (CALC) in millimolesllitre`.\n",
    "\n",
    "The data is obtained from 'Physical Characteristics of Urines With and Without Crystals',a chapter from Springer Series in Statistics.\n",
    "\n",
    "https://link.springer.com/chapter/10.1007/978-1-4612-5098-2_45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding II\n",
    "\n",
    "There are two datasets, The original dataset and the generated dataset, we will be using both to compare and contrast features etc.\n",
    "\n",
    "Files from the generated dataset:\n",
    "\n",
    "- `train.csv` - the training dataset; `target` is the likelihood of a kidney stone being present\n",
    "- `test.csv` - the test dataset; your objective is to `predict the probability of target`\n",
    "- `sample_submission.csv` - a sample submission file in the correct format\n",
    "\n",
    "Files from the original dataset:\n",
    "\n",
    "- `kindey_stone_urine_analysis.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding III, Understanding our Features in Depth\n",
    "\n",
    "- `specific gravity`: Urine specific gravity is a laboratory test that shows the concentration of all chemical particles in the urine. The normal range for urine specific gravity is `1.005 to 1.030`. USG is the ratio of the density (mass of a unit volume) of urine to the density (mass of the same unit volume) of a reference substance (water). USG values vary between 1.000 and 1.040 g/mL, USG less than 1.008 g/mL is regarded as dilute, and USG greater than 1.020 g/mL is considered concentrated. USG was higher in patients with stone formation than in those without stone formation (1.018±0.007 vs. 1.017±0.007). Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7844516/ \n",
    "\n",
    "- `pH` : When the pH of urine drops below 5.5, urine becomes saturated with uric acid crystals, a condition known as hypercalciuria. When there is too much uric acid in the urine, stones can form. Uric acid stones are more common in people who consume large amounts of protein, such as that found in red meat or poultry.\n",
    "Source: https://www.hopkinsmedicine.org/health/conditions-and-diseases/kidney-stones\n",
    "\n",
    "- `osmolarity (mOsm)` : Osmolarity refers to the number of solute particles per 1 L of solvent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.3 (v3.8.3:6f8c8320e9, May 13 2020, 16:29:34) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "pandas version: 2.0.0\n",
      "matplotlib version: 3.7.1\n",
      "NumPy version: 1.24.2\n",
      "SciPy version: 1.10.1\n",
      "IPython version: 8.12.0\n",
      "scikit-learn version: 1.2.2\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Modelling Libraries\n",
    "\n",
    "We will use the popular scikit-learn library to develop our machine learning algorithms. In sklearn, algorithms are called Estimators and implemented in their own classes. For data visualization, we will use the matplotlib and seaborn library. Below are common classes to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making our datasets available in our coding environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/input/playground-series-s3e12\"\n",
    "TRAIN_FILENAME = \"/Users/richeyjay/Desktop/Kidney_Stone_PredictionML/env/Code/train.csv\"\n",
    "TEST_FILENAME = \"/Users/richeyjay/Desktop/Kidney_Stone_PredictionML/env/Code/test.csv\"\n",
    "SUBMISSION_FILENAME = \"/Users/richeyjay/Desktop/Kidney_Stone_PredictionML/env/Code/sample_submission.csv\"\n",
    "ORIGINAL_PATH = \"/kaggle/input/media-campaign-cost-prediction\"\n",
    "ORIGINAL_FILENAME = \"/Users/richeyjay/Desktop/Kidney_Stone_PredictionML/env/Code/kidney_stone_urine_analysis.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in our csv files and putting them into a dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv(ORIGINAL_FILENAME)\n",
    "train_data = pd.read_csv(TRAIN_FILENAME)\n",
    "test_data = pd.read_csv(TEST_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e76c816a5280c6bce1276d697eadf7631eb3c3ad42339ee7c294666adf523803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
